{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas sklearn nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3 - Text Mining\n",
    "\n",
    "Project management and tools for health informatics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Download and prepare data:\n",
    "\n",
    "**Do not alter the code in this Section!**\n",
    "\n",
    "The code in this section downloads the [IMDB IMDB Large Movie Review Dataset]('https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz') which is the dataset you will be working on in this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "from urllib.request import urlretrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('aclImdb'):\n",
    "    # download data:\n",
    "    urlretrieve('https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz', 'aclImdb.tar.gz')\n",
    "\n",
    "    # unzip data:\n",
    "    with tarfile.open('aclImdb.tar.gz') as file:\n",
    "        file.extractall('./')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Some helper Functions:\n",
    "\n",
    "**Do not alter the code in this Section!**\n",
    "\n",
    "This section contains the code for some helper functions that will be useful for solving the assignment. Example code on how to use the functions is provided in section 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from typing import Literal, Tuple, Iterable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for loading data into a pandas dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(split:Literal['train', 'test'], texts_per_class:int=500) -> pd.DataFrame:\n",
    "    ''' Loads the data into a pandas dataframe.'''\n",
    "    paths  = []\n",
    "    labels = []\n",
    "\n",
    "    for label in ('pos', 'neg'):\n",
    "        # get all files in the folder:\n",
    "        files = os.listdir(os.path.join('aclImdb', split, label))[:texts_per_class]\n",
    "\n",
    "        # append them to the lists:\n",
    "        paths.extend([os.path.join('aclImdb', split, label, f) for f in files])\n",
    "        labels.extend([label] * len(files))\n",
    "\n",
    "    return pd.DataFrame({'path':paths, 'label':labels})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for loading a specific text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_text(path:str) -> str:\n",
    "    ''' Reads a single text given the path. '''\n",
    "    # read file from disk:\n",
    "    with open(path, 'r', encoding='utf8') as file:\n",
    "        s = file.read()\n",
    "\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for iterating through multiple texts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_texts(data:pd.DataFrame) -> Iterable[Tuple[str, str]]:\n",
    "    ''' Iterates through a pandas dataframe. '''\n",
    "\n",
    "    for path in data['path'].values:\n",
    "        # read file from disk:\n",
    "        with open(path, 'r', encoding='utf8') as file:\n",
    "            text = file.read()\n",
    "\n",
    "        yield text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Your Code:\n",
    "\n",
    "**Alter the code below to complete the assignment!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = load_data('train')\n",
    "data_test  = load_data('test')\n",
    "data_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing the texts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample code: load a single text\n",
    "load_text(data_train.loc[0, 'path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample code: iterate through all texts\n",
    "for text in iterate_texts(data_train[:20]):\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A simple pipeline:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**White-Space tokenization:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text:str):\n",
    "    ''' An example tokenization function. '''\n",
    "\n",
    "    # simple white-space tokenization:\n",
    "    return text.lower().split()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bag-of-words Embedding:**\n",
    "\n",
    "See documentation of [sklearn.feature_extraction.text.CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# create a simple bag of words embedding:\n",
    "bow = CountVectorizer(\n",
    "\n",
    "    # the next line converts the filepaths to the actual texts:\n",
    "    preprocessor = load_text,\n",
    "\n",
    "    # tokenization function from above:\n",
    "    tokenizer = tokenize\n",
    "\n",
    ")\n",
    "\n",
    "# train the embedding:\n",
    "embeddings_train = bow.fit_transform(data_train['path'].values)\n",
    "\n",
    "# vectorize test data:\n",
    "embeddings_test = bow.transform(data_test['path'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classification with a linear SVM**\n",
    "\n",
    "See documentation of [sklearn.svm.LinearSVC](https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html#sklearn.svm.LinearSVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "svm = LinearSVC()\n",
    "\n",
    "# train classifier:\n",
    "svm.fit(embeddings_train, data_train['label'].values)\n",
    "\n",
    "# test classifier:\n",
    "predictions = svm.predict(embeddings_test)\n",
    "\n",
    "# Calculate Accuracy:\n",
    "print('Accuracy:', accuracy_score(data_test['label'].values, predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
